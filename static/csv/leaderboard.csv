Model,Toxicity,Stereotype Bias,Adversarial Robustness,OOD Robustness,Robustness to Adv. Demonstrations,Privacy,Machine Ethics,Fairness
mistralai/Mistral-7B-Instruct-v0.1,24.48,92.67,36.62,81.12,57.93,75.84,,84.97
Open-Orca/Mistral-7B-OpenOrca,30.12,79.33,52.08,73.4,62.15,77.36,34.21/0.05,66.76
garage-bAInd/Stable-Platypus2-13B,34.41,81.33,,84.87,34.4,73.6,68.35,
stabilityai/stablelm-3b-4e1t,,85.67,41.2,67.85,33.34,71.15,56.98,59.74
adept/persimmon-8b-base,35.96,79.33,66.98,,39.86,83.5,,99.27
Tulu-2-13b,44.8,89.33,46.7,70.17,71.17,78.9,36.64,97.9
Zephyr-7B-beta,31.97,92.67,30.92,65.58,68.68,84.18,41.03,95.07
Llama2-7b-chat,80,97.6,51.01,75.65,55.54,97.39,40.58,100
Vicuna,28,81,52.16,59.1,57.99,72.96,48.22,85.53
Alpaca,22,43,46.43,51.79,34.15,46.39,30.43,92.63
MPT,40,84.6,46.2,64.26,58.25,78.93,26.11,100
Falcon,39,87,43.98,51.45,33.95,70.26,50.28,100
RedPajama,18,73,44.81,54.21,58.51,76.64,27.49,100
Claude,,100,57.98,85.77,72.97,85.35,85.17,96.81
GPT-3.5,47,87,56.69,73.58,81.28,70.13,86.38,77.57
GPT-4,41,77,64.04,87.55,77.94,66.11,76.6,63.67
